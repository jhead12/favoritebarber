### Example env file â€” DO NOT COMMIT real secrets
# Copy to `.env` and fill values locally or use secret manager

# Database
DATABASE_URL=postgresql://postgres:password@localhost:5432/rateyourbarber
REDIS_URL=redis://redis:6379

# Third-party API keys (placeholders)
YELP_API_KEY=your_yelp_api_key_here
GOOGLE_VISION_API_KEY=your_google_vision_api_key_here
GEOCODING_API_KEY=your_geocoding_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here

# Storage
S3_BUCKET=your-bucket
S3_ENDPOINT=
S3_ACCESS_KEY_ID=
S3_SECRET_ACCESS_KEY=

# App settings
PORT=3000
RADIUS_DEFAULT_M=48280
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# Admin/API
ADMIN_API_KEY=replace_with_admin_jwt_or_store_securely
# Environment example for local development
DATABASE_URL=postgresql://postgres:password@localhost:5432/rateyourbarber
YELP_API_KEY=your_yelp_api_key_here
LOG_LEVEL=info
SENTRY_DSN=
USE_YELP_GRAPHQL=false
ENABLE_COST_TRACKING=true
REDIS_URL=redis://redis:6379
YELP_API_KEY=your_yelp_api_key_here
GOOGLE_VISION_API_KEY=your_google_vision_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here

# Local LLM (Ollama) for privacy-first NLP
# Install: brew install ollama
# Pull model: ollama pull llama3.2:3b
# Run: ollama serve (in separate terminal)
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
OLLAMA_TIMEOUT=30000

S3_BUCKET=your-bucket
S3_ENDPOINT=
S3_ACCESS_KEY_ID=
S3_SECRET_ACCESS_KEY=
GEOCODING_API_KEY=
PORT=3000
RADIUS_DEFAULT_M=48280

# LLM orchestration and provider keys
# Primary provider selection (e.g., ollama, openai, huggingface, replicate)
LLM_PROVIDER=ollama
# Fallback providers (comma-separated)
LLM_PROVIDER_FALLBACK=openai,ollama
# Hugging Face / Inference API key
HF_API_KEY=
HUGGINGFACE_MODEL=google/flan-t5-small
# Replicate API key
REPLICATE_API_KEY=
# Global LLM tuning
LLM_TIMEOUT_MS=12000
LLM_MAX_RETRIES=1

# Environment example for local development
DATABASE_URL=postgresql://postgres:password@postgres:5432/rateyourbarber
REDIS_URL=redis://redis:6379
YELP_API_KEY=your_yelp_api_key_here
GOOGLE_VISION_API_KEY=your_google_vision_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here

# Local LLM (Ollama) for privacy-first NLP
# Install: brew install ollama
# Pull model: ollama pull llama3.2:3b
# Run: ollama serve (in separate terminal)
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
OLLAMA_TIMEOUT=30000

S3_BUCKET=your-bucket
S3_ENDPOINT=
S3_ACCESS_KEY_ID=
S3_SECRET_ACCESS_KEY=
GEOCODING_API_KEY=
PORT=3000
RADIUS_DEFAULT_M=48280

# LLM orchestration and provider keys
# Primary provider selection (e.g., ollama, openai, huggingface, replicate)
LLM_PROVIDER=ollama
# Fallback providers (comma-separated)
LLM_PROVIDER_FALLBACK=openai,ollama
# Hugging Face / Inference API key
HF_API_KEY=
HUGGINGFACE_MODEL=google/flan-t5-small
# Replicate API key
REPLICATE_API_KEY=
# Global LLM tuning
LLM_TIMEOUT_MS=12000
LLM_MAX_RETRIES=1

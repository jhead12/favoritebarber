### Example env file — DO NOT COMMIT real secrets
# Copy to `.env` and fill values locally or use a secret manager.

# -------------------------
# Database & cache
# -------------------------
DATABASE_URL=postgresql://postgres:password@localhost:5432/rateyourbarber
REDIS_URL=redis://127.0.0.1:6379

# -------------------------
# Third-party API keys
# -------------------------
YELP_API_KEY=your_yelp_api_key_here
GOOGLE_VISION_API_KEY=your_google_vision_api_key_here
GEOCODING_API_KEY=your_geocoding_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here

# -------------------------
# Storage
# -------------------------
S3_BUCKET=your-bucket
S3_ENDPOINT=
S3_ACCESS_KEY_ID=
S3_SECRET_ACCESS_KEY=

# -------------------------
# App settings
# -------------------------
PORT=3000
RADIUS_DEFAULT_M=48280
LOG_LEVEL=info
SENTRY_DSN=
USE_YELP_GRAPHQL=false
ENABLE_COST_TRACKING=true

# -------------------------
# Local LLM (Ollama) — optional
# Install: `brew install ollama`
# Pull model: `ollama pull llama3.2:3b`
# Run: `ollama serve` in a separate terminal
# -------------------------
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
OLLAMA_TIMEOUT=30000

# -------------------------
# Admin / API
# -------------------------
ADMIN_API_KEY=replace_with_admin_jwt_or_store_securely

# -------------------------
# LLM orchestration and provider keys
# Primary provider selection (e.g., ollama, openai, huggingface, replicate)
# Fallback providers (comma-separated)
# -------------------------
LLM_PROVIDER=ollama
LLM_PROVIDER_FALLBACK=openai,ollama
HF_API_KEY=
HUGGINGFACE_MODEL=google/flan-t5-small
REPLICATE_API_KEY=
LLM_TIMEOUT_MS=12000
LLM_MAX_RETRIES=1

# Notes:
# - Copy this file to `.env` and populate real secrets before running the services.
# - Use `DISABLE_JOBS=true` or `NODE_ENV=test` to skip background jobs during test runs.
